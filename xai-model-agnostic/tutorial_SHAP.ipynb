{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b65def18",
   "metadata": {},
   "source": [
    "![logo](https://github.com/donatellacea/DL_tutorials/blob/main/notebooks/figures/1128-191-max.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb24f4af",
   "metadata": {},
   "source": [
    "# Model-Agnostic Interpretation with SHAP\n",
    "\n",
    "In this Notebook we will demonstrate how to use the SHapley Additive exPlanations (SHAP) and interpret the Shapley values, plots, and other information produced by the SHAP package.\n",
    "\n",
    "This tutorial is under the MPL 2.0 licence and is based on a [tutorial by Andrew Fairless](https://afairless.com/shap-tutorial/).\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9985159",
   "metadata": {},
   "source": [
    "### Setup Colab environment\n",
    "\n",
    "If you installed the packages and requirments on your own machine, you can skip this section and start from the import section.\n",
    "Otherwise you can follow and execute the tutorial on your browser. In order to start working on the notebook, click on the following button, this will open this page in the Colab environment and you will be able to execute the code on your own.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/HelmholtzAI-Consultants-Munich/Zero2Hero---Introduction-to-XAI/blob/master/xai-model-agnostic/tutorial_SHAP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf284707",
   "metadata": {},
   "source": [
    "Now that you are visualizing the notebook in Colab, run the next cell to install the packages we will use.\n",
    "There are few things you should follow in order to properly set the notebook up:\n",
    "\n",
    "1. Warning: This notebook was not authored by Google. *Click* on 'Run anyway'.\n",
    "2. When the installation commands are done, there might be \"Restart runtime\" button at the end of the output. Please, *click* it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d91bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e12523",
   "metadata": {},
   "source": [
    "By running the next cell you are going to create a folder in your Google Drive. All the files for this tutorial will be uploaded to this folder. After the first execution you might receive some warning and notification, please follow these instructions:\n",
    "1. Permit this notebook to access your Google Drive files? *Click* on 'Yes', and select your account.\n",
    "2. Google Drive for desktop wants to access your Google Account. *Click* on 'Allow'.\n",
    "\n",
    "At this point, a folder has been created and you can navigate it through the lefthand panel in Colab, you might also have received an email that informs you about the access on your Google Drive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb4d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder in your Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8bb193",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4910437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't run this cell if you already cloned the repo in the first part of the tutorial\n",
    "!git clone https://github.com/HelmholtzAI-Consultants-Munich/Zero2Hero---Introduction-to-XAI.git\n",
    "# or !git clone git@github.com:HelmholtzAI-Consultants-Munich/Zero2Hero---Introduction-to-XAI.git   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd294d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Zero2Hero---Introduction-to-XAI/xai-model-agnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e36efe4",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d191ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "import shap\n",
    "\n",
    "from utils.check_file import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f34a31",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Now, we fix the random seeds to ensure reproducible results, as we work with (pseudo) random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f19032",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-14T11:51:10.503453Z",
     "iopub.status.busy": "2022-09-14T11:51:10.502768Z",
     "iopub.status.idle": "2022-09-14T11:51:10.506221Z",
     "shell.execute_reply": "2022-09-14T11:51:10.505737Z"
    }
   },
   "outputs": [],
   "source": [
    "# assert reproducible random number generation\n",
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff80af92",
   "metadata": {},
   "source": [
    "## The California Housing Dataset: Data Loading and Model Training\n",
    "\n",
    "Let's use the California housing data set. The dataset is introduced in detail in the permutation importance notebook. Check it out, if you like to have more information on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "calif_house_data = fetch_california_housing()\n",
    "X = pd.DataFrame(calif_house_data['data'], columns = calif_house_data['feature_names'])\n",
    "y = pd.DataFrame(calif_house_data['target'], columns=['Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03936320",
   "metadata": {
    "cell_marker": "'''",
    "lines_to_next_cell": 2
   },
   "source": [
    "For the sake of runtime we limit ourselves to only the first 2000 samples. We will split parts of the data, so the model can not use all the available information for training. That way, we can also check performance and interpretation results on previously unseen data, mirroring the most probable practical use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b21508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only first 2000 samples and convert all data frames to numpy array, which is required for SHAP\n",
    "feature_names = X.columns\n",
    "X = X[:2000].to_numpy()\n",
    "y = y[:2000].to_numpy()\n",
    "\n",
    "# split off the test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=seed)\n",
    "print('Number of training samples: {}'.format(X_train.shape[0]))\n",
    "print('Number of test samples: {}'.format(X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480d6509",
   "metadata": {},
   "source": [
    "We'll create a Kernel ridge regression model with an RBF kernel to predict our *price* target variable from the other features, after they have been properly rescaled to each have zero mean and unit standard deviation.  \n",
    "Don't worry for now if you are not familiar with the model. It is just meant as a protoype of a model that is not straightforward to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"preprocessing\", StandardScaler()),\n",
    "    (\"model\", KernelRidge(kernel=\"rbf\"))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a28159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the model performing reasonably on the training data?\n",
    "print('Model Performance on training data: {}'.format(pipe.score(X_train, y_train)))\n",
    "\n",
    "# is the model performing reasonably on the test data?\n",
    "print('Model Performance on test data: {}'.format(pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934228f4",
   "metadata": {},
   "source": [
    "Since model training and tuning is not a focus of this course, we will not try to improve the model performance further.  \n",
    "**Note:** you should keep in mind that interpreting a low performing model can lead to wrong conclusions.\n",
    "\n",
    "Now, that we trained a regression model which predicts the prices relatively well but might be a bit hard to interpet directly, we can make use of SHAP to help us out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4d632f",
   "metadata": {},
   "source": [
    "## Now, what does my model actually think is important in the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e397e02",
   "metadata": {},
   "source": [
    "### SHapley Additive exPlanations (SHAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517608e",
   "metadata": {},
   "source": [
    "Let's use **SHAP** to explain our model's predictions.\n",
    "\n",
    "We prepared a small [video lecture](https://vimeo.com/745352008/3168320cef) for you to help you understand how SHAP works and how Shapley values are computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3037c3bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-14T11:51:28.430435Z",
     "iopub.status.busy": "2022-09-14T11:51:28.430220Z",
     "iopub.status.idle": "2022-09-14T11:51:28.444005Z",
     "shell.execute_reply": "2022-09-14T11:51:28.443314Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import VimeoVideo\n",
    "\n",
    "VimeoVideo(\"745352008?h=3168320cef\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e0b09c",
   "metadata": {},
   "source": [
    "To summarize, SHAP is a method that enables a fast computation of Shapley values and can be used to explain the prediction of an instance x by computing the contribution (Shapley value) of each feature to the prediction. We get contrastive explanations that compare the prediction with the average prediction. The fast computation makes it possible to compute the many Shapley values needed for the global model interpretations. With SHAP, global interpretations are consistent with the local explanations, since the Shapley values are the “atomic unit” of the global interpretations. If you use LIME for local explanations and permutation feature importance for global explanations, you lack a common foundation. SHAP provides KernelSHAP, an alternative, kernel-based estimation approach for Shapley values inspired by local surrogate models, as well as TreeSHAP, an efficient estimation approach for tree-based models. \n",
    "\n",
    "\n",
    "**Note:** this method is a **local** method which means that it does only provide explanations for individual samples. However, the individual explanations can be used to also get **global** interpretations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d0ee8b",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Now lets use SHAP to get some insights into the Kernel Ridge regression model we trained above. The *shap.Explainer()* function uses the shap values to explain any machine learning model. Here we use KernelSHAP (*shap.KernelExplainer()*) to calculate our Shapley values. KernalSHAP is an alternative, kernel-based estimation approach for Shapley values inspired by local surrogate models. If you are calculating Shapley values for tree-based methods, you could use TreeSHAP (*shap.TreeExplainer()*) instaed, which provides a fast, model-specific alternative to KernelSHAP. As data you should use a subset of your original training data, as the Shapley value calculation takes quite some time. That is why we limit ourselves to only the first 100 examples of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf017f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first 100 rows\n",
    "n_rows = 100\n",
    "X_shap = pd.DataFrame(X_train[:n_rows], columns = feature_names)\n",
    "y_shap = pd.DataFrame(y_train[:n_rows], columns = ['Price'])\n",
    "predictions_shap = pd.DataFrame(pipe.predict(X_train[:n_rows]), columns = ['Predicted Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6210094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-14T11:51:33.130905Z",
     "iopub.status.busy": "2022-09-14T11:51:33.130532Z",
     "iopub.status.idle": "2022-09-14T11:52:30.864413Z",
     "shell.execute_reply": "2022-09-14T11:52:30.863619Z"
    }
   },
   "outputs": [],
   "source": [
    "# run the SHAP Java initializer, that is needed later to create the plot\n",
    "shap.initjs()\n",
    "\n",
    "# run SHAP\n",
    "explainer = shap.KernelExplainer(pipe.predict, X_shap)\n",
    "shap_values = np.reshape(explainer.shap_values(X_shap), (n_rows,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c2c9f5",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Notice that the shapley values matrix is the same size as our input matrix that contains all the feature values for each observation (i.e., each row of the matrix). That means that there is one Shapley value for each entry in our feature matrix. Hence, each observation (row) has a Shapley value for each of its features (columns) that explains that feature's contribution to the model's prediction for that observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c516b32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-14T11:52:30.868439Z",
     "iopub.status.busy": "2022-09-14T11:52:30.867998Z",
     "iopub.status.idle": "2022-09-14T11:52:30.874422Z",
     "shell.execute_reply": "2022-09-14T11:52:30.873702Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Features matrix - # samples: {}, # features: {}'.format(X_shap.shape[0], X_shap.shape[1]))\n",
    "print('SHAP values matrix - # samples: {}, # features: {}'.format(shap_values.shape[0], shap_values.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a8fc9f",
   "metadata": {
    "cell_marker": "'''",
    "lines_to_next_cell": 0
   },
   "source": [
    "The SHAP values explain why a prediction for a single observation is different from the average prediction for all the observations in the data set. Here's our model's average prediction for our data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408f8e54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-14T11:52:30.887882Z",
     "iopub.status.busy": "2022-09-14T11:52:30.887355Z",
     "iopub.status.idle": "2022-09-14T11:52:30.893444Z",
     "shell.execute_reply": "2022-09-14T11:52:30.892743Z"
    }
   },
   "outputs": [],
   "source": [
    "# average prediction for the dataset\n",
    "print('Models average prediction for our data set: {}'.format(explainer.expected_value[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e741821",
   "metadata": {},
   "source": [
    "### Local Explanations with SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245fd295",
   "metadata": {},
   "source": [
    "The SHAP package provides some visualizations to help us understand how much each feature contributes to each prediction. Let's look at a prediction for a single observation (row) in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d762cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_of_interest = 1\n",
    "print('Models prediction for the observation of interest: {}'.format(predictions_shap.iloc[observation_of_interest]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb0ab8",
   "metadata": {},
   "source": [
    "#### Decision Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5797cd1",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Here is the SHAP package's *decision plot* for explaining why a single\n",
    "    observation deviates from the average prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c86543",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-14T11:52:30.896613Z",
     "iopub.status.busy": "2022-09-14T11:52:30.896264Z",
     "iopub.status.idle": "2022-09-14T11:52:31.156041Z",
     "shell.execute_reply": "2022-09-14T11:52:31.155041Z"
    }
   },
   "outputs": [],
   "source": [
    "shap.decision_plot(\n",
    "    explainer.expected_value, \n",
    "    shap_values[observation_of_interest], \n",
    "    X_shap.iloc[observation_of_interest])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a48abe",
   "metadata": {
    "cell_marker": "'''",
    "lines_to_next_cell": 2
   },
   "source": [
    "It's probably the easiest to read this plot from the bottom to the top. At the\n",
    "    bottom, the blue line starts at the average prediction for the\n",
    "    whole data set. Then as we move up the plot row by row, we're looking at\n",
    "    each feature's effect on the prediction for our single observation, given the \n",
    "    current set of feature values. If the line moves a lot to the left or right, \n",
    "    then the feature for that row changes the prediction by a lot.\n",
    "\n",
    "**Note:** The Shapley value can be misinterpreted. The Shapley value of a feature value is not the difference of the predicted value after removing the feature from the model training. The interpretation of the Shapley value is: Given the current set of feature values, the contribution of a feature value to the difference between the actual prediction and the mean prediction is the estimated Shapley value.\n",
    "\n",
    "As we move from the bottom to the top of the plot, we notice that *AveRooms*, *Population*, *AveBedrms* and *AveOccup* have only a small impact on the prediction, whereas *Latitude*, *MedInc* and *HouseAge* have larger effects.\n",
    "\n",
    "The values in parentheses in each row show the value for each feature for the\n",
    "    houses in this census block. So, we can see that houses in this block\n",
    "    are 14 years old on average and have an average occupancy of 2.55. Compared to\n",
    "    all the houses in the data set, these values increase the median price of the houses.\n",
    "\n",
    "As we move further up the plot, we notice that the census block's *Latitude* strongly decreases the predicted median price, according to our model.\n",
    "\n",
    "When we sum up all the SHAP-calculated effects of the features, we see that\n",
    "    the model predicts that the median price for houses in this census block\n",
    "    is about 1.12. This can be read off the plot directly: it's where the blue squiggly line ends up at the top of the plot.\n",
    "    The value for this sample is below 1.89 (from which the decision plot started at the bottom), the average predicted median price \n",
    "    for all houses in all the census blocks in the data set we used to computed the shapley values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541fe126",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "</font>\n",
    "\n",
    "Now, let's do a litte exercise to see if you understood this plot. Therefore, please execute the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fbeb22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-14T11:52:31.160629Z",
     "iopub.status.busy": "2022-09-14T11:52:31.160181Z",
     "iopub.status.idle": "2022-09-14T11:52:31.403404Z",
     "shell.execute_reply": "2022-09-14T11:52:31.402381Z"
    }
   },
   "outputs": [],
   "source": [
    "observation_of_interest_exercise = 96\n",
    "print('Models prediction for the observation of interest: {}'.format(predictions_shap.iloc[observation_of_interest_exercise]))\n",
    "\n",
    "shap.decision_plot(\n",
    "    explainer.expected_value, \n",
    "    shap_values[observation_of_interest_exercise], \n",
    "    X_shap.iloc[observation_of_interest_exercise])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811d547e",
   "metadata": {},
   "source": [
    "Now, look at the plot and add the correct answers to the following lines of code:\n",
    "- Which feature has the highest impact on the predicted price? *most_important_feature*\n",
    "- Does the age of the house (39) increase or decrease the predicted price?\n",
    "- Is the final prediction of the price higher or lower than the average prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef3a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-14T11:52:31.408124Z",
     "iopub.status.busy": "2022-09-14T11:52:31.407555Z",
     "iopub.status.idle": "2022-09-14T11:52:31.414285Z",
     "shell.execute_reply": "2022-09-14T11:52:31.413732Z"
    }
   },
   "outputs": [],
   "source": [
    "most_important_feature = None # 'feature_name'\n",
    "house_age = None # 'increase' or 'decrease'\n",
    "final_prediction = None # 'higher' or 'lower'\n",
    "\n",
    "check_task_1(most_important_feature, house_age, final_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b86f69",
   "metadata": {},
   "source": [
    "#### Force Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bd3be9",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "The SHAP package provides another type of plot, the *force plot*, to visualize\n",
    "    the same information as the *decision plot* that we discussed above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786fc18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-14T11:52:31.419127Z",
     "iopub.status.busy": "2022-09-14T11:52:31.417715Z",
     "iopub.status.idle": "2022-09-14T11:52:32.138098Z",
     "shell.execute_reply": "2022-09-14T11:52:32.137429Z"
    }
   },
   "outputs": [],
   "source": [
    "shap.force_plot(\n",
    "    explainer.expected_value, \n",
    "    shap_values[observation_of_interest], \n",
    "    X_shap.iloc[observation_of_interest], \n",
    "    matplotlib=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1d133c",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "In this *force plot*, the information that we saw in the *decision plot* is\n",
    "    vertically squashed, or compressed.  The effects of all the features now\n",
    "    appear on a single row, instead of each feature appearing on its own row.\n",
    "    This visualization is more compact, but we can still see the same\n",
    "    information that we saw in the *decision plot*.\n",
    "\n",
    "The average prediction for all houses in all the census blocks is labeled\n",
    "    as the *base value* here which is about 1.89. The predicted median price for houses in this\n",
    "    census block is 1.12 and is labeled as the *f(x)*.\n",
    "\n",
    "Features that increase the predicted price from the *base value* are in red and\n",
    "    are distinguished from each other by arrows pointing to the right.  Features\n",
    "    that decrease the predicted price are in blue and have left-pointing\n",
    "    arrows.  Features with larger effects on the prediction occupy more space\n",
    "    in the row of arrows.  The two sets of features point to the *output value*.\n",
    "    The names of the features and their values are printed below the row of\n",
    "    arrows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9ec42",
   "metadata": {},
   "source": [
    "### Global Explanations with SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc149b0f",
   "metadata": {},
   "source": [
    "#### Force Plot\n",
    "\n",
    "Now that we understand the *force plot* for a single observation, we can look\n",
    "    at a force plot for our 100 selected observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7034c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-14T11:52:32.154053Z",
     "iopub.status.busy": "2022-09-14T11:52:32.152692Z",
     "iopub.status.idle": "2022-09-14T11:52:32.183292Z",
     "shell.execute_reply": "2022-09-14T11:52:32.182721Z"
    }
   },
   "outputs": [],
   "source": [
    "shap.force_plot(\n",
    "    explainer.expected_value, \n",
    "    shap_values, \n",
    "    X_shap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd591d0",
   "metadata": {
    "cell_marker": "'''",
    "lines_to_next_cell": 0
   },
   "source": [
    "In the *force plot* for a single observation, we had a horizontal row of red\n",
    "    and blue arrows.  For this *force plot* of many observations, the rows of\n",
    "    red and blue arrows have been rotated so that the arrows for a single\n",
    "    observation are now vertical.  We can look horizontally across our entire\n",
    "    sampled data set and easily see approximately how many observations have\n",
    "    high predictions or average predictions or low predictions (where the red\n",
    "    and blue areas meet). We can also see which features tend to push these\n",
    "    predictions up or down. Hover with your mouse over section of the plot to get information about single samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e459ac6",
   "metadata": {},
   "source": [
    "#### Feature Importances Summary Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd194f6",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "The *force plot* for many observations is great for looking at the model's\n",
    "    predictions with granularity.  But what if we want a simpler summary of\n",
    "    how important each feature is in making predictions for the entire data\n",
    "    set - something like *feature importance*?\n",
    "\n",
    "The SHAP package provides this as a *summary plot*.  Here it is for our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d8eb94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-14T11:52:32.188062Z",
     "iopub.status.busy": "2022-09-14T11:52:32.186660Z",
     "iopub.status.idle": "2022-09-14T11:52:32.324711Z",
     "shell.execute_reply": "2022-09-14T11:52:32.324092Z"
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values, \n",
    "    X_shap, \n",
    "    plot_type='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae18e2a",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Those feature importances are calculated simply by taking the\n",
    "    absolute values of all the Shapley values and averaging them for each\n",
    "    feature.  Look closely, and you can see that the calculation below matches\n",
    "    the plot *summary plot* above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d12a55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-14T11:52:32.329665Z",
     "iopub.status.busy": "2022-09-14T11:52:32.328248Z",
     "iopub.status.idle": "2022-09-14T11:52:32.337246Z",
     "shell.execute_reply": "2022-09-14T11:52:32.336746Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(np.abs(shap_values).mean(axis=0), index=feature_names).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b774c4",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "Just to make sure we understand what's happening here. Remember, each row is an observation, which represents a census block of houses,\n",
    "    and we have 100 census blocks.  Each column is a feature, and there are 8 features.\n",
    "\n",
    "All we did in the calculation above was to average all the (absolute values of\n",
    "    the) 100 Shapley values in each column.  That gave us 8 sums, one for each\n",
    "    feature, and those are our 8 feature importances for this model.  It's that\n",
    "    simple.\n",
    "\n",
    "Let's pause and consider this for a moment, because this is a really important\n",
    "    point:  the feature importances for the entire model are calculated\n",
    "    directly from their importances for individual observations.  In other\n",
    "    words, the importances are consistent between the model's global behavior\n",
    "    and its local behavior.  This consistency is a remarkable and really\n",
    "    important characteristic that many model interpretability methods do not\n",
    "    offer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e02372f",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "The SHAP package also provides a more granular look at feature importances for\n",
    "    the entire data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9118fa59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-14T11:52:32.365015Z",
     "iopub.status.busy": "2022-09-14T11:52:32.363668Z",
     "iopub.status.idle": "2022-09-14T11:52:32.621873Z",
     "shell.execute_reply": "2022-09-14T11:52:32.621229Z"
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values, \n",
    "    X_shap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9448a5",
   "metadata": {
    "cell_marker": "'''",
    "lines_to_next_cell": 0
   },
   "source": [
    "Here the Shapley values of every observation are plotted for each feature.\n",
    "    Additionally, the coloring indicates whether low (or high) values of each\n",
    "    feature increase (or decrease) the model's predictions.\n",
    "\n",
    "For example, we can see that high median incomes (*MedInc*) increase the\n",
    "    predictions of house prices (i.e., the Shapley values are greater than zero)\n",
    "    while low median incomes decrease those predictions (i.e., the Shapley\n",
    "    values are < 0).  Also, the effects of *MedInc* on the model's predictions\n",
    "    exhibit a positively skewed distribution:  most values of *MedInc*\n",
    "    decrease the model's predictions, while a long tail of high *MedInc*\n",
    "    values increase the model's predictions.\n",
    "\n",
    "With *AveOccup*, there is a similar effect in the opposite direction. Low values of average occupancy\n",
    "    increase the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c5493",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "#### Question 1: What does the shapley value tell you about the effect of the feature on a prediction?\n",
    "\n",
    "<font color='grey'>\n",
    "\n",
    "#### Your Answer: \n",
    "\n",
    "It tells you by how much the specific feature is moving the sample's prediction away from the mean prediction of all samples.\n",
    "\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "#### Question 2: What are the differences to the permutation importance method?\n",
    "\n",
    "<font color='grey'>\n",
    "\n",
    "#### Your Answer: \n",
    "\n",
    "- The shapley-value itself tells you something about the absolute effect of a feature on the output.\n",
    "- To get the importance of a feature all possible combinations of feature subsets with and without the feature of interest are computed.\n",
    "- Shapley is based only on model prediction and not on performance metric.\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "#### Question 3: What is the main limitation of shapley values and why?\n",
    "\n",
    "<font color='grey'>\n",
    "\n",
    "#### Your Answer: \n",
    "\n",
    "That it is computationally expensive, especially for large models and large features sets, as you need to compute all possible combinations of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e596a2ae",
   "metadata": {},
   "source": [
    "This concludes our exploration of how to use Shapley values and the SHAP\n",
    "    package. To learn more about Shapley values, the SHAP package, and how these are used to\n",
    "    help us interpret our machine learning models, please refer to these\n",
    "    resources:\n",
    "\n",
    "\n",
    "- [A Unified Approach to Interpreting Model Predictions](https://arxiv.org/abs/1705.07874)\n",
    "    > Scott Lundberg, Su-In Lee\n",
    "\n",
    "- [Consistent feature attribution for tree ensembles](https://arxiv.org/abs/1706.06060)\n",
    "    > Scott M. Lundberg, Su-In Lee\n",
    "\n",
    "- [Consistent Individualized Feature Attribution for Tree Ensembles](https://arxiv.org/abs/1802.03888)\n",
    "    > Scott M. Lundberg, Gabriel G. Erion, Su-In Lee\n",
    "\n",
    "- [A game theoretic approach to explain the output of any machine learning model.](https://github.com/slundberg/shap)\n",
    "    >\n",
    "\n",
    "- [Interpretable Machine Learning:  A Guide for Making Black Box Models Explainable.  5.9 Shapley Values](https://christophm.github.io/interpretable-ml-book/shapley.html)\n",
    "    > Christoph Molnar, 2019-12-17\n",
    "\n",
    "- [Interpretable Machine Learning:  A Guide for Making Black Box Models Explainable.  5.10 SHAP (SHapley Additive exPlanations](https://christophm.github.io/interpretable-ml-book/shap.html)\n",
    "    > Christoph Molnar, 2019-12-17\n",
    "\n",
    "- [Interpretable Machine Learning with XGBoost](https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27?gi=187ef710fdda)\n",
    "    > Scott Lundberg, Apr 17, 2018\n",
    "\n",
    "- [Explain Your Model with the SHAP Values](https://towardsdatascience.com/explain-your-model-with-the-shap-values-bc36aac4de3d)\n",
    "    > Dataman, Sep 14, 2019\n",
    "\n",
    "\n",
    "Additionally, Christoph Molnar's book and Tim Miller's paper can provide further insight into the\n",
    "    challenges and promise of machine learning interpretability:\n",
    "\n",
    "- [Interpretable Machine Learning:  A Guide for Making Black Box Models Explainable.](https://christophm.github.io/interpretable-ml-book/)\n",
    "    > Christoph Molnar, 2019-12-17\n",
    "\n",
    "- [Explanation in Artificial Intelligence: Insights from the Social Sciences](https://arxiv.org/abs/1706.07269)\n",
    "    > Tim Miller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ac8ef0",
   "metadata": {},
   "source": [
    "## Extra Material: Interpretation of a Random Forest Classifier that Predicts Wine Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2789762d",
   "metadata": {},
   "source": [
    "Let's use the wine quality dataset. Two datasets are included, related to red and white vinho verde wine samples, from the north of Portugal. The goal is to model wine quality based on physicochemical tests.\n",
    "\n",
    "<center><img src=\"./figures/red_wine.jpg\" width=\"1200\" /></center>\n",
    "\n",
    "<font size=1> Source:\\\n",
    "https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140f53bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421cb062",
   "metadata": {},
   "source": [
    "Now, let's have a look at the description of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bade6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wine_data['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f650f29a",
   "metadata": {},
   "source": [
    "Let's put all of our data into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cd0598",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(wine_data['data'], columns = wine_data['feature_names'])\n",
    "y = pd.DataFrame(wine_data['target'], columns=['Quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29caebef",
   "metadata": {},
   "source": [
    "and see how many samples and features we have in the dataset and how their values are distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e03c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Features: {}'.format(list(X.columns)))\n",
    "print('# samples: {}, # features: {}'.format(len(X.index), len(X.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e03c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e640b265",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2210aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e146fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb937d1",
   "metadata": {
    "cell_marker": "'''"
   },
   "source": [
    "The data set has 178 observations, 13 features, and 1 target variable. The target variable *quality* is categorical with three classes (low, medium, good quality), so we can predict the classes using the other available features with a classification model of our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9df4fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all data frames to numpy array, which is required for SHAP\n",
    "feature_names = X.columns\n",
    "X = X.to_numpy()\n",
    "y = np.reshape(y.to_numpy(), (-1))\n",
    "\n",
    "# split off the test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=seed)\n",
    "print('Number of training samples: {}'.format(X_train.shape[0]))\n",
    "print('Number of test samples: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cbab6b",
   "metadata": {},
   "source": [
    "We'll create a Random Forest Classifier to predict our *quality* target variable from the other features, after they have been properly rescaled to each have zero mean and unit standard deviation.  \n",
    "Don't worry for now if you are not familiar with the model. It is just meant as a protoype of a model that is not straightforward to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"preprocessing\", StandardScaler()),\n",
    "    (\"model\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f47f3f3",
   "metadata": {},
   "source": [
    "Now that the model is fit, let's check its performance as measured by the mean accuracy metric for both the training and the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a28159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the model performing reasonably on the training data?\n",
    "print('Model Performance on training data: {}'.format(pipe.score(X_train, y_train)))\n",
    "\n",
    "# is the model performing reasonably on the test data?\n",
    "print('Model Performance on test data: {}'.format(pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097e177a",
   "metadata": {},
   "source": [
    "**Task:** ..."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "id,colab_type,-all",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "zero2hero",
   "language": "python",
   "name": "zero2hero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1296530d03d149de975d73bd04f7e3ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8ff7a37e4d7547c08d094381c036af01",
       "placeholder": "​",
       "style": "IPY_MODEL_558a13970e844208bf1761edb872c327",
       "tabbable": null,
       "tooltip": null,
       "value": " 100/100 [00:57&lt;00:00,  1.82it/s]"
      }
     },
     "51c66596191848be86531e43e63cf12e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7a732f175e6047f4a3de6598477f5bd2",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_92b0b28156ed4813bfac7289fdd29537",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     },
     "558a13970e844208bf1761edb872c327": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5a4840cf306d4baf98f395b1238b58cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d39b39148e4b41b09ece715caddabb2f",
       "placeholder": "​",
       "style": "IPY_MODEL_ab834c9304f44f0e936a1339069afa9d",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "6f81b88027cd4e778537a0a6fda7e4e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5a4840cf306d4baf98f395b1238b58cb",
        "IPY_MODEL_51c66596191848be86531e43e63cf12e",
        "IPY_MODEL_1296530d03d149de975d73bd04f7e3ff"
       ],
       "layout": "IPY_MODEL_7d547d01526342d0842c52d9780a6633",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7a732f175e6047f4a3de6598477f5bd2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d547d01526342d0842c52d9780a6633": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ff7a37e4d7547c08d094381c036af01": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "92b0b28156ed4813bfac7289fdd29537": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ab834c9304f44f0e936a1339069afa9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d39b39148e4b41b09ece715caddabb2f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
