Terminology
==============

**Explainability or Interpretability?** 
There is no standard and generally accepted definition, and sometimes people use these two terms interchangeably.
Despite the confusion, we believe there is a difference between the two.

The Royal Society defines [1]:
- **Interpretability**: implies some sense of understanding how the technology works
- **Explainability**: implies that a wider range of users can understand why or how a conclusion was reached

Therefore when we focus on interpretability, our goal is to understand exactly why and how the model is generating predictions. In order to do that, we need to observe and understand the inner mechanics of the AI/ML method, and we can say that we are dealing with a glass-box model. On the other hand, when our deal is explainability, we are focusing on the decision-making process because the ML model is like a black box and we cannot understand the inner mechanisms. What we can do is try to explain the output of the ML model in human terms.

In this course, we will not focus on intrinsic methods that are interpretable by construction, but we will only focus on explainability, looking at some of the main popular post hoc methods.

References
-----------

[1] Explainable AI: The basics, The Royal Society, 2019. Link: https://royalsociety.org/-/media/policy/projects/explainable-ai/AI-and-interpretability-policy-briefing.pdf
