{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](https://github.com/donatellacea/DL_tutorials/blob/main/notebooks/figures/1128-191-max.png?raw=true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Model-Specific Interpretation with Grad-CAM\n",
    "\n",
    "In this Notebook we will demonstrate how to use Grad-CAM, a gradient-based pixel attribution method, for understanding which parts of the image the model considers more relevant when making its prediction. We will be using the pre-trained ResNet-50 and play around with various images\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "### Setup Colab environment\n",
    "\n",
    "If you installed the packages and requirements on your own machine, you can skip this section and start from the import section.\n",
    "Otherwise, you can follow and execute the tutorial on your browser. In order to start working on the notebook, click on the following button, this will open this page in the Colab environment and you will be able to execute the code on your own.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/HelmholtzAI-Consultants-Munich/XAI-Tutorials/blob/SummerAcademy-2023/xai-model-specific/Tutorial_Grad-CAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "Now that you opened the notebook in Colab, follow the next step:\n",
    "1. Run this cell to connect your Google Drive to Colab and install packages\n",
    "2. Allow this notebook to access your Google Drive files. Click on 'Yes', and select your account.\n",
    "3. \"Google Drive for desktop wants to access your Google Account\". Click on 'Allow'.\n",
    "At this point, a folder has been created in your Drive and you can navigate it through the lefthand panel in Colab, you might also have received an email that informs you about the access on your Google Drive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive\n",
    "!git clone --branch SummerAcademy-2023 https://github.com/HelmholtzAI-Consultants-Munich/XAI-Tutorials.git\n",
    "%cd XAI-Tutorials/xai-model-specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Let's start with importing all required Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5GIj5Oyq1HwH"
   },
   "outputs": [],
   "source": [
    "# Installing the necessary packages\n",
    "import utils\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# add Grad-CAM model to path\n",
    "import sys  \n",
    "sys.path.append('../data_and_models/')\n",
    "from model_gradcam import GradCamModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fix the random seeds to ensure reproducible results, as we work with (pseudo) random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert reproducible random number generation\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mTUk2DGa1X5_"
   },
   "source": [
    "## Grad-CAM\n",
    "\n",
    "Before starting with the hands-on part, we prepared a small video that summarizes the concepts that will be useful for the rest of the session. Take some time to watch our [Introduction to Grad-CAM](https://xai-tutorials.readthedocs.io/en/latest/_model_specific_xai/Grad-CAM.html).\n",
    "\n",
    "### Loading and preparing the input image\n",
    "\n",
    "We need to perform the following steps to have the input image ready to be fed to the model:\n",
    "\n",
    "* Load the image\n",
    "* Convert the image to RGB channel\n",
    "* Transform the image:\n",
    "  * Convert to PIL format\n",
    "  * Resize to lower resolution\n",
    "  * Convert to tensor dtype\n",
    "  * Normalize the pixel values\n",
    "* Unsqueeze the image to add a batch dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "CIzW8wu31YPV",
    "outputId": "b2171fb9-8c46-488f-f9f0-f1a29e77c793"
   },
   "outputs": [],
   "source": [
    "# read and visualize the image\n",
    "path_to_img = '../data_and_models/images/Iguana.jpeg'\n",
    "img = utils.read_img(path_to_img)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# define the transformations (here we are using the ImageNet transformations)\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# next transform the so it is ready to be given to the model\n",
    "trans_img = utils.transform_img(img, mean, std)\n",
    "print('Transformed image size: ', trans_img.size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "AkBbIUWn2c-2"
   },
   "source": [
    "### Loading a Grad-Cam model\n",
    "\n",
    "For this tutorial, we are going to use the GradCamModel class which includes a pretrained ResNet-50 model and functions for returning the feature map activations and gradients. If you are interested you will find this class in ```gradcam_model.py```.\n",
    "\n",
    "Let's start loading the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the GradCamModel\n",
    "gcmodel = GradCamModel()\n",
    "\n",
    "# set the evaluation mode\n",
    "_ = gcmodel.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass\n",
    "\n",
    "After instantiating GradCamModel, we make a forward pass through the network and see what the ResNet-50 predicts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "out = gcmodel(trans_img) \n",
    "pred = out.argmax(dim=1)\n",
    "\n",
    "print('Classification result:', pred.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "oRp4DwKskOqT"
   },
   "source": [
    "Click [this link](https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/) to identify the class name and see if the prediction is correct. \n",
    "\n",
    "Now that we verified that our model correctly classifies the iguana, we are going to do the back-propagation with the logit of the predicted class in the ImageNet dataset.\n",
    "\n",
    "Grad-CAM uses the feature maps produced by the last convolutional layer of a CNN. The authors of Grad-CAM argue, _“we can expect the last convolutional layers to have the best compromise between high-level semantics and detailed spatial information.”_\n",
    "\n",
    "Grad-CAM is applied to a neural network that has finished training. The weights of the neural network are fixed. We feed an image into the network to calculate the Grad-CAM heatmap for a specific image and a chosen class of interest.\n",
    "\n",
    "### Grad-CAM Details\n",
    "\n",
    "Let us assume $y^c$ is the score for class $c$ i.e., the output for class $c$ before the softmax.\n",
    "\n",
    "**Step 1: Computing Gradient**\n",
    "\n",
    "Compute the gradient of $y^c$ with respect to the feature map activation $A^k$ of a convolution layer i.e., $\\frac {∂y^c}{∂A^k}$\n",
    "\n",
    "**Step 2: Calculate Global Average Pooling (GAP) of the feature map.**\n",
    "     \n",
    "Global average pool the gradients over the width dimension (indexed by $i$) and the height dimension (indexed by $j$) to obtain weights ${\\alpha_k^c}$\n",
    "\n",
    "  $\n",
    "  {\\alpha_k^c} = \\frac {1}{Z} \\sum_{i} \\sum_{j} \\frac {∂y^c}{∂A^k_{ij}}\n",
    "  $\n",
    "\n",
    "**Step 3: Calculate Final Grad-CAM Localization Map**\n",
    "     \n",
    "Perform a weighted combination of the feature map activations $A^k$ where the weights are the ${\\alpha_k^c}$ we just calculated and keep only positive contributions applying a ReLU function.\n",
    "\n",
    "  $\n",
    "  L^c_{Grad-CAM} = ReLU (\\sum_k {\\alpha_k^c} A^k)\n",
    "  $\n",
    "\n",
    "#### Exercise 1\n",
    "Follow the steps described above and change the **None** with your code to complete the Grad-CAM algorithm.\n",
    "\n",
    "HINTS: \n",
    "\n",
    "1. Don't forget the batch dimension - gradients will have a size of $[Batch \\times k \\times i \\times j]$\n",
    "2. Use numpy to apply the ReLU function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_localization_map(gcmodel, img, out, c):\n",
    "\n",
    "    # Step 1 - Gradient output y wrt. to activation map\n",
    "    # get the gradient of the output with respect to the parameters of the model\n",
    "    out[:,c].backward(retain_graph=True)\n",
    "    # pull the gradients out of the model\n",
    "    gradients = gcmodel.get_gradient()\n",
    "\n",
    "    # Step 2 - Global average pooling\n",
    "    # pool the gradients across the channels\n",
    "    pooled_gradients = None # insert your code here\n",
    "\n",
    "    # Step 3 - Weighted combination of influence and feature maps\n",
    "    # get the activations of the last convolutional layer\n",
    "    activations = gcmodel.get_activations(img).detach()\n",
    "    # weight the channels by corresponding gradients\n",
    "    for i in range(activations.size(1)):\n",
    "        activations[:, i, :, :] *= pooled_gradients[i]\n",
    "    # average the channels of the activations\n",
    "    localization_map = torch.sum(activations, dim=1).squeeze()\n",
    "    # convert the map to be a numpy array\n",
    "    localization_map = localization_map.numpy()\n",
    "    # relu on top of the localization map\n",
    "    localization_map = None # insert your code here\n",
    "\n",
    "    return localization_map\n",
    "\n",
    "def convert_to_heatmap(localization_map, img):\n",
    "    # normalize the localization_map\n",
    "    localization_map /= np.max(localization_map)\n",
    "    # resize to image size\n",
    "    heatmap = cv.resize(localization_map, (img.shape[1], img.shape[0]))\n",
    "    # normalize to [0, 255] range and convert to unsigned int\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    return heatmap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap\n",
    "\n",
    "Call calculate_heatmap to get the Res-Net GradCAM output for class 'iguana'\n",
    "\n",
    "Next, process the result for visualisation and visualise it along with the original image and the Grad-CAM heat-map projected onto the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localization_map = calculate_localization_map(gcmodel, trans_img, out, c=pred.item())\n",
    "\n",
    "heatmap = convert_to_heatmap(localization_map, img)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(131)\n",
    "plt.imshow(img)\n",
    "plt.title('Original image')\n",
    "plt.subplot(132)\n",
    "plt.imshow(localization_map.squeeze())\n",
    "plt.title('Heat-Map for the image')\n",
    "plt.subplot(133)\n",
    "plt.imshow(heatmap, cmap='jet', alpha=0.5)\n",
    "plt.imshow(img, alpha=0.5)\n",
    "plt.title('Grad-CAM heat-map projected onto the original image')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's look at a different image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and visualize an image\n",
    "img = utils.read_img('../data_and_models/images/cat_and_dog.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# next transform it so it is ready to be given to the model\n",
    "trans_img = utils.transform_img(img, mean, std)\n",
    "print('Transformed image size: ', trans_img.size())\n",
    "\n",
    "# forward pass\n",
    "out = gcmodel(trans_img) # img)\n",
    "pred = out.argmax(dim=1)\n",
    "\n",
    "print('Classification result:', pred.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the model predicting? Let's look at the top two predictions and try and understand each!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sort= torch.argsort(out, descending=True)\n",
    "top_ten = pred_sort[0,:10]\n",
    "print('Top ten probabilities: ', top_ten)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a moment to identify the class names [ImageNet class list](https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/).\n",
    "\n",
    "Now let's use GradCAM to try and understand where the model is focusing for specific probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_cat = calculate_localization_map(gcmodel, trans_img, out, c=282)\n",
    "heatmap_dog = calculate_localization_map(gcmodel, trans_img, out, c=231)\n",
    "\n",
    "heatmap_catn = convert_to_heatmap(heatmap_cat, img)\n",
    "heatmap_dogn = convert_to_heatmap(heatmap_dog, img)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(141)\n",
    "plt.imshow(heatmap_cat.squeeze())\n",
    "plt.title('Heatmap for class  garden cat')\n",
    "plt.subplot(142)\n",
    "plt.imshow(heatmap_catn, cmap='jet', alpha=0.4)\n",
    "plt.imshow(img, alpha=0.6)\n",
    "plt.title('Grad-CAM cat projection')\n",
    "plt.subplot(143)\n",
    "plt.imshow(heatmap_dog.squeeze())\n",
    "plt.title('Heatmap for class  dog')\n",
    "plt.subplot(144)\n",
    "plt.imshow(heatmap_dogn, cmap='jet', alpha=0.4)\n",
    "plt.imshow(img, alpha=0.6)\n",
    "plt.title('Grad-CAM dog projection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Congratulations! You completed this tutorial.\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "#### Questionnaire: What did we learn today?\n",
    "<font color='black'>\n",
    "Look at [this short questionnaire](https://docs.google.com/presentation/d/1vd_HfkBD4FokoAM2el4T1rXWnD7_0FAEvxk4HgiYjXs/present?slide=id.g1499f1249e3_0_0) to revise what you have learned in our session so far! Think about the answers and discuss them with your group.\n",
    "\n",
    "<font color='grey'>\n",
    "    \n",
    "#### Your Answer: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "#### Question: What do you think are the strengths and weaknesses of Grad-CAM on image classification?\n",
    "\n",
    "<font color='grey'>\n",
    "\n",
    "#### Your Answer: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "* Look at the top-10 classes of the model - can you see a pattern?\n",
    "* Can you implement the occlusion technique, see [here](https://towardsdatascience.com/inshort-occlusion-analysis-for-explaining-dnns-d0ad3af9aeb6), by removing the areas of the dog and cat on the last image and see what you get?\n",
    "\n",
    "## Further reading:\n",
    "\n",
    "Here is the original [GradCAM paper](https://arxiv.org/pdf/1610.02391.pdf)\n",
    "\n",
    "This tutorial was based on: https://medium.com/@stepanulyanin/grad-cam-for-resnet152-network-784a1d65f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "XplainableAITutorial2V2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
