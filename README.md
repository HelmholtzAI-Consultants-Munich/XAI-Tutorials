![stability-stable](https://img.shields.io/badge/stability-stable-green.svg)

[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#https://github.com/HelmholtzAI-Consultants-Munich/XAI-Tutorials)

# Tutorials for eXplainable Artificial Intelligence (XAI) methods

This repository contains a collection of self-explanatory tutorials for different model-agnostic and model-specific XAI methods.
Each tutorial comes in a Jupyter Notebook wich contains a short video lecture and practical exercises.
The material has already been used in the context of two courses: the Zero to Hero Summer Academy (fully online) and ml4hearth (hybrid setting).
The course material adjusted accordingly to the availabel time frame, the schedule and other relevant information about the specific course are available in the respective branches.
The material is self-explanatory and can be also be consumed offline.

The learning objectives are:

- understand the importance of interpretability
- discover the existing methods, in particular perturbation features importance, LIME, SHAP, FGC and Grad-CAM
- learn how to interpret the outputs and graphs of those methods with hands-on exercises
- learn to chose which method is suitable for a specific task


## List of Tutorials for Model-Agnostic Methods

- Permutation Feature Importance
- SHapley Additive exPlanations (SHAP)
- Local Interpretable Model-Agnostic Explanations

## List of Tutorials for Model-Specific Methods

- Forest-Guided Clustering
- Grad-CAM

## Requirements and Setup

It is possible either to create an environment and install all the necessary packages locally (using the requirements.txt file) or to execute the notebooks on the browser, clicking the 'Open in Colab' button. This second option doesn't require any further installation, but the user must have acces to a Google account.

## Contributions

Comments and input are very welcome! Please, if you have a suggestion or you think something should be changed, open an issue or submit a pull request. 
