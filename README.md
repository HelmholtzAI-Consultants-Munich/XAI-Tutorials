# XAI Tutorials @ ml4earth Hackathon

This course is an introduction to eXplainable Artificial Intelligence (XAI).

In this course the learner will:

- understand the importance of interpretability
- discover the existing methods, in particular perturbation features importance, SHAP and Grad-CAM
- put your hands on three tutorials to uncover how to interpret the outputs and graphs of those methods

Workshop website: http://ml4earth.de/workshop/

Share document for questions: https://notes.desy.de/br0Ko_TWQPm2auZRIr_5Tg?both

## Agenda
The course is helded online on September 22nd from 1 pm to 4 pm

| Time          | Content |
| ------------- | -------- |
| 13.00 - 13.30 | Introduction to XAI |
| 13.30 - 14.30 | Tutorial on XAI model-agnostic methods |
| 14.30 - 15.00 | Break |
| 15.00 - 15.55 | Tutorials on “XAI in deep learning-based image analysis” |
| 15.55 - 16.00 | Wrap-up and conclusions |

## Slides

### General Introduction
- [Introduction to XAI](https://docs.google.com/presentation/d/1GOXOHEPFg_K9VVfZDAcfx8wy3UIsjLYNEJjQTe-38Rw/edit?usp=sharing)


### Model-Agnostic Methods
- [Introduction to Permutation Feature Importance](https://docs.google.com/presentation/d/1AbmzTS4RU2MOhSl231rPKDt432_SX4i7YvZY4apNZJU/edit#slide=id.g138313838d0_1_828)
- [Introduction to SHAP](https://docs.google.com/presentation/d/1JGat4jwQd54jExmQiXmDvLSpgHvOC6fZAmWRwL-Cl18/edit#slide=id.g138313838d0_8_676)


### Model-Specific Methods

- [Introduction to Grad-CAM](https://docs.google.com/presentation/d/1vd_HfkBD4FokoAM2el4T1rXWnD7_0FAEvxk4HgiYjXs/edit#slide=id.g13d689e73d4_0_285)


## Notebooks with Tutorials

- Introduction to Permutation Feature Importance: [Notebook](https://github.com/HelmholtzAI-Consultants-Munich/XAI-Tutorials/blob/ml4earth-Hackathon/xai-model-agnostic/tutorial_permutation_FI.ipynb), [Video](https://vimeo.com/745319412/1e5bd15ff7), [Questionnaire](https://www.learningsnacks.de/report/#/register/11766/850f448a-a2cd-48ba-9a0a-2d4040e6868e)

- Introduction to SHAP: [Notebook](https://github.com/HelmholtzAI-Consultants-Munich/XAI-Tutorials/blob/ml4earth-Hackathon/xai-model-agnostic/tutorial_SHAP.ipynb), [Video](https://vimeo.com/745352008/3168320cef), [Questionnaire](https://www.learningsnacks.de/report/#/register/11767/5711c97e-b990-4541-9d71-c5bd8d0f6bbd)

- Introduction to Grad-CAM: [Notebook Part 1](https://github.com/HelmholtzAI-Consultants-Munich/XAI-Tutorials/blob/ml4earth-Hackathon/xai-model-specific/Grad-CAM/part1.ipynb), [Notebook Part 2](https://github.com/HelmholtzAI-Consultants-Munich/XAI-Tutorials/blob/ml4earth-Hackathon/xai-model-specific/Grad-CAM/part2.ipynb), [Video1](https://vimeo.com/745320494/0b8be077b3), [Video2](https://vimeo.com/745319946/fcd327fc80), [Questionnaire](https://www.learningsnacks.de/report/#/register/11758/2bdd9bcd-76d5-4790-8941-8062a4818592)


## Additional materials

If you are interested in tutorials on other model-agnostic and model-specific interpretability methods, pelase visit out [XAI-tutorials](https://github.com/HelmholtzAI-Consultants-Munich/XAI-Tutorials) github repository.

### Literature

[1] Explainable AI: the basics, The Royal Society, 2019. Link: https://royalsociety.org/-/media/policy/projects/explainable-ai/AI-and-interpretability-policy-briefing.pdf

[2] Interpretable Machine Learning: A Guide for Making Black Box Models Explainable, Christoph Molnar, 2022. Link: https://christophm.github.io/interpretable-ml-book/neural-networks.html
